{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74defd9a-167e-417b-8921-1cefdd1bdc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class BERTSemanticSearch:\n",
    "    def __init__(self, data_file, model_name='bert-base-uncased'):\n",
    "        self.data = self._load_data(data_file)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.embeddings = self._generate_embeddings()\n",
    "\n",
    "    def _load_data(self, data_file):\n",
    "        \"\"\"Load material data from a JSON file.\"\"\"\n",
    "        import json\n",
    "        with open(data_file, 'r') as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    def _generate_embeddings(self):\n",
    "        \"\"\"Generate BERT embeddings for all descriptions.\"\"\"\n",
    "        descriptions = [item['description'] for item in self.data]\n",
    "        return self._encode_texts(descriptions)\n",
    "\n",
    "    def _encode_texts(self, texts):\n",
    "        \"\"\"Generate BERT embeddings for a list of texts.\"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            texts, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            # Use the [CLS] token's embedding as the sentence embedding\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        return cls_embeddings.numpy()\n",
    "\n",
    "    def _cosine_similarity_to_percentage(self, cosine_similarity):\n",
    "        \"\"\"Convert cosine similarity score to a percentage (0-100%).\"\"\"\n",
    "        return round(((1-cosine_similarity) * 100),2)\n",
    "\n",
    "\n",
    "    def search(self, queries, top_k=5):\n",
    "        \"\"\"Perform semantic search for a list of queries.\"\"\"\n",
    "        query_embeddings = self._encode_texts(queries)\n",
    "        distances = cdist(query_embeddings, self.embeddings, metric='cosine')\n",
    "        results = []\n",
    "\n",
    "        for i, query in enumerate(queries):\n",
    "            ranked_indices = np.argsort(distances[i])[:top_k]\n",
    "            matches = [\n",
    "                {\n",
    "                    \"material_number\": self.data[idx]['material_number'],\n",
    "                    \"description\": self.data[idx]['description'],\n",
    "                    # \"score\": 1 - distances[i, idx]  # Cosine similarity (1 - distance)\n",
    "                    \"score\": self._cosine_similarity_to_percentage(distances[i, idx])\n",
    "                }\n",
    "                for idx in ranked_indices\n",
    "            ]\n",
    "            results.append({\"query\": query, \"matches\": matches})\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e185f8bf-741f-43df-ab23-055683b99a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: metal rod\n",
      "  - {'material_number': '10000000-0475', 'description': 'Office Supplies - stapler', 'score': 86.41}\n",
      "  - {'material_number': '10000000-0726', 'description': 'Office Supplies - stapler', 'score': 86.41}\n",
      "  - {'material_number': '10000000-0132', 'description': 'Office Supplies - stapler', 'score': 86.41}\n",
      "  - {'material_number': '10000000-0951', 'description': 'Office Supplies - stapler', 'score': 86.41}\n",
      "  - {'material_number': '10000000-0218', 'description': 'Office Supplies - stapler', 'score': 86.41}\n",
      "Query: engine oil\n",
      "  - {'material_number': '10000000-0627', 'description': 'Office Supplies - stapler', 'score': 86.64}\n",
      "  - {'material_number': '10000000-0554', 'description': 'Office Supplies - stapler', 'score': 86.64}\n",
      "  - {'material_number': '10000000-0951', 'description': 'Office Supplies - stapler', 'score': 86.64}\n",
      "  - {'material_number': '10000000-0435', 'description': 'Office Supplies - stapler', 'score': 86.64}\n",
      "  - {'material_number': '10000000-0884', 'description': 'Office Supplies - stapler', 'score': 86.64}\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the semantic search engine\n",
    "    search_engine = BERTSemanticSearch(data_file='materials.json')\n",
    "\n",
    "    # Example search queries\n",
    "    queries = [\"metal rod\", \"engine oil\"]\n",
    "    results = search_engine.search(queries)\n",
    "\n",
    "    # Print results\n",
    "    for result in results:\n",
    "        print(f\"Query: {result['query']}\")\n",
    "        for match in result['matches']:\n",
    "            print(f\"  - {match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479a325-29e8-4312-a4e7-a25dcc36e64c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
